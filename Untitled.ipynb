{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59e0e52-d6b1-4cb1-8e3c-64a582cb915e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "Complete, runnable postprocess script for one ELMFIRE case.\n",
    "\n",
    "What it does:\n",
    "- Loads/plots fuel map (categorized colormap)\n",
    "- Loads weather rasters and plots histograms (WS, WD, M1, M10, M100)\n",
    "- Loads TOA stack, builds burn-area history\n",
    "- Loads VIIRS points, filters to extent, groups by half-day, convex hulls, burn-area history\n",
    "- Overlays VIIRS dots on base map and simulated burned extent for selected times\n",
    "- Computes Cohen's Kappa per selected frames by rasterizing VIIRS hulls and comparing to Ï†-binary\n",
    "- Saves figures + metrics.json\n",
    "\n",
    "Adjust the PATH CONSTANTS block for your case.\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "import os, re, glob, json, math\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "import rasterio\n",
    "from rasterio.features import rasterize\n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "from rasterio.enums import Resampling as ResampEnum\n",
    "\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, Polygon, MultiPoint\n",
    "from shapely.ops import unary_union\n",
    "\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from datetime import timedelta\n",
    "from zoneinfo import ZoneInfo\n",
    "from datetime import datetime\n",
    "\n",
    "# -------------------------\n",
    "# ===== PATH CONSTANTS ====\n",
    "# -------------------------\n",
    "# CASE_ROOT = Path(\"/global/home/users/yirenqin712/scratch/yirenqin712/ELMFIRE_SIMULATION/VnV_Suite/tubbs_fire\").resolve()\n",
    "\n",
    "# # Inputs\n",
    "# FUELMAP_PATH   = CASE_ROOT / \"data/fuels_and_topography/fbfm40b.tif\"\n",
    "# WX_WS_PATH     = CASE_ROOT / \"data/weather/ws.tif\"\n",
    "# WX_WD_PATH     = CASE_ROOT / \"data/weather/wd.tif\"\n",
    "# WX_M1_PATH     = CASE_ROOT / \"data/weather/m1.tif\"\n",
    "# WX_M10_PATH    = CASE_ROOT / \"data/weather/m10.tif\"\n",
    "# WX_M100_PATH   = CASE_ROOT / \"data/weather/m100.tif\"\n",
    "# TOA_GLOB       = str(CASE_ROOT / \"outputs\" / \"time_of_arrival_*.tif\")\n",
    "# PHI_GLOB       = str(CASE_ROOT / \"outputs\" / \"phi_0000001_*.tif\")\n",
    "# VIIRS_DIR      = CASE_ROOT / \"data/observation/viirs\"                      # expects viirs_*.shp\n",
    "\n",
    "# # Outputs\n",
    "# FIG_DIR = CASE_ROOT / \"figures\"\n",
    "# REP_DIR = CASE_ROOT / \"report\"\n",
    "# for p in [FIG_DIR, REP_DIR]:\n",
    "#     p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# # Map extent + CRS for plotting overlays (adjust if needed)\n",
    "# # [left, right, bottom, top] in projected CRS (e.g., UTM)\n",
    "# # If you already know your extent, set it here; otherwise it's computed from fuel map reproject.\n",
    "# MAP_CRS = \"EPSG:32610\"  # UTM zone (adjust per case)\n",
    "OUT_CRS = \"EPSG:4326\"   # Plotting in lon/lat for base map\n",
    "# MAP_EXTENT_OVERRIDE: Optional[List[float]] = None  # or [xmin, xmax, ymin, ymax] in MAP_CRS\n",
    "\n",
    "# # -------------------------\n",
    "# # ====== UTILITIES =========\n",
    "# # -------------------------\n",
    "\n",
    "# def savefig(fig, name: str):\n",
    "#     \"\"\"Save a figure into the case-local figures/ folder as PDF and close it.\"\"\"\n",
    "#     out = FIG_DIR / f\"{name}.pdf\"\n",
    "#     fig.savefig(out, format=\"pdf\")  # no bbox_inches\n",
    "#     plt.close(fig)\n",
    "#     return out\n",
    "\n",
    "def ensure_1band_array(data: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Squeeze raster read output to 2D [H,W].\"\"\"\n",
    "    if data.ndim == 3 and data.shape[0] == 1:\n",
    "        return data[0]\n",
    "    if data.ndim == 2:\n",
    "        return data\n",
    "    raise ValueError(f\"Unexpected raster array shape: {data.shape}\")\n",
    "\n",
    "def read_raster(path: Path) -> Tuple[np.ndarray, rasterio.Affine, dict]:\n",
    "    with rasterio.open(path) as src:\n",
    "        arr = src.read(1, masked=True)\n",
    "        transform = src.transform\n",
    "        meta = src.meta.copy()\n",
    "    return arr, transform, meta\n",
    "\n",
    "def reproject_to(src_path: Path, dst_crs: str) -> Tuple[np.ndarray, rasterio.Affine, dict]:\n",
    "    with rasterio.open(src_path) as src:\n",
    "        transform, width, height = calculate_default_transform(\n",
    "            src.crs, dst_crs, src.width, src.height, *src.bounds\n",
    "        )\n",
    "        dst = np.empty((height, width), dtype=src.meta[\"dtype\"])\n",
    "        reproject(\n",
    "            source=rasterio.band(src, 1),\n",
    "            destination=dst,\n",
    "            src_transform=src.transform,\n",
    "            src_crs=src.crs,\n",
    "            dst_transform=transform,\n",
    "            dst_crs=dst_crs,\n",
    "            resampling=Resampling.nearest\n",
    "        )\n",
    "        meta = src.meta.copy()\n",
    "        meta.update({\"crs\": dst_crs, \"transform\": transform, \"width\": width, \"height\": height})\n",
    "    return dst, transform, meta\n",
    "\n",
    "def array_extent(transform: rasterio.Affine, width: int, height: int) -> List[float]:\n",
    "    left, bottom = transform * (0, height)\n",
    "    right, top   = transform * (width, 0)\n",
    "    return [left, right, bottom, top]\n",
    "\n",
    "# -------------------------\n",
    "# ====== FUEL MAP =========\n",
    "# -------------------------\n",
    "def create_custom_fuel_colormap(fuel_data: np.ndarray):\n",
    "    # Reclassify: 0=structure(91), 1=water(98), 2=nonburnable(92/93/99), 3=vegetation(other)\n",
    "    reclassified = np.full(fuel_data.shape, 3, dtype=np.uint8)\n",
    "    reclassified[fuel_data == 91] = 0\n",
    "    reclassified[fuel_data == 98] = 1\n",
    "    reclassified[np.isin(fuel_data, [92, 93, 99])] = 2\n",
    "\n",
    "    colors = [\"saddlebrown\", \"lightblue\", \"gray\", \"lightgreen\"]\n",
    "    cmap = mcolors.ListedColormap(colors, name=\"custom_fuel\")\n",
    "    norm = mcolors.BoundaryNorm(np.arange(-0.5, 4.5, 1), cmap.N)\n",
    "    return reclassified, cmap, norm\n",
    "\n",
    "def plot_fuel_map(fuel_map_path: Path, ax: Optional[plt.Axes] = None, show_colorbar: bool = True,\n",
    "                  dst_crs: str = OUT_CRS, **imshow_kwargs):\n",
    "    dst, transform, meta = reproject_to(fuel_map_path, dst_crs)\n",
    "    # mask nodata\n",
    "    nodata = meta.get(\"nodata\", None)\n",
    "    if nodata is not None:\n",
    "        dst = np.ma.masked_equal(dst, nodata)\n",
    "\n",
    "    fuel_reclass, fuel_cmap, fuel_norm = create_custom_fuel_colormap(dst)\n",
    "\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    extent = array_extent(transform, meta[\"width\"], meta[\"height\"])\n",
    "    imshow_kwargs.setdefault(\"extent\", extent)\n",
    "    imshow_kwargs.setdefault(\"origin\", \"upper\")\n",
    "\n",
    "    im = ax.imshow(fuel_reclass, cmap=fuel_cmap, norm=fuel_norm, **imshow_kwargs)\n",
    "    ax.set_aspect(\"equal\")\n",
    "    if show_colorbar:\n",
    "        cbar = plt.colorbar(im, ax=ax, fraction=0.046, pad=0.02, ticks=[0,1,2,3])\n",
    "        cbar.set_label(\"Fuel Type\")\n",
    "        cbar.ax.set_yticklabels([\"S(91)\", \"W(98)\", \"N(92,93,99)\", \"V(others)\"])\n",
    "    return im, ax, extent\n",
    "\n",
    "# -------------------------\n",
    "# ====== WEATHER HISTS =====\n",
    "# -------------------------\n",
    "def plot_wx_hist(ax: plt.Axes, filepath: Path, bins: int = 60, title: Optional[str] = None) -> None:\n",
    "    arr, _, meta = read_raster(filepath)\n",
    "    data = np.asarray(arr).ravel()\n",
    "    if np.ma.isMaskedArray(data):\n",
    "        data = data.compressed()\n",
    "    data = data[np.isfinite(data)]\n",
    "\n",
    "    ax.hist(data, bins=bins, density=True)\n",
    "    ax.set_ylabel(\"PDF [-]\")\n",
    "    if title:\n",
    "        ax.set_title(title)\n",
    "\n",
    "# -------------------------\n",
    "# ===== TOA + PHI LOADING ==\n",
    "# -------------------------\n",
    "def extract_timestamp_from_phi_name(fname: str) -> Optional[int]:\n",
    "    m = re.search(r\"phi_0000001_(\\d+)\\.tif$\", fname)\n",
    "    return int(m.group(1)) if m else None\n",
    "\n",
    "def load_toa_stack(toa_glob: str) -> Tuple[List[Path], List[np.ndarray], List[float], rasterio.Affine, dict]:\n",
    "    paths = sorted([Path(p) for p in glob.glob(toa_glob)])\n",
    "    if not paths:\n",
    "        raise FileNotFoundError(f\"No TOA rasters found with pattern: {toa_glob}\")\n",
    "    arrays, times = [], []\n",
    "    transform, meta = None, None\n",
    "    for p in paths:\n",
    "        arr, tform, m = read_raster(p)\n",
    "        arrays.append(np.array(arr))\n",
    "        # infer time from filename if present, else index\n",
    "        m2 = re.search(r\"time_of_arrival_(\\d+)\\.tif$\", p.name)\n",
    "        times.append(float(m2.group(1)) if m2 else float(len(times)))\n",
    "        if transform is None:\n",
    "            transform, meta = tform, m\n",
    "    return paths, arrays, times, transform, meta\n",
    "\n",
    "def load_phi_paths(phi_glob: str) -> List[Path]:\n",
    "    paths = sorted([Path(p) for p in glob.glob(phi_glob)])\n",
    "    if not paths:\n",
    "        raise FileNotFoundError(f\"No PHI rasters found with pattern: {phi_glob}\")\n",
    "    return paths\n",
    "\n",
    "def phi_to_binary(phi_path: Path) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Convert Ï† field to binary burn map on its own grid.\n",
    "    Assumption: burned = (phi <= 0). Returns (binary, valid_mask).\n",
    "    \"\"\"\n",
    "    with rasterio.open(phi_path) as src:\n",
    "        phi = src.read(1, masked=True)\n",
    "        valid = ~phi.mask if np.ma.isMaskedArray(phi) else np.ones_like(phi, dtype=bool)\n",
    "        burned = (phi <= 0)\n",
    "        burned = np.where(valid, burned, 0).astype(np.uint8)\n",
    "        return burned, valid\n",
    "\n",
    "# -------------------------\n",
    "# ===== VIIRS PROCESSING ===\n",
    "# -------------------------\n",
    "def load_viirs_points(viirs_dir: Path) -> gpd.GeoDataFrame:\n",
    "    shp_list = sorted(viirs_dir.glob(\"*.shp\"))\n",
    "    if not shp_list:\n",
    "        raise FileNotFoundError(f\"No VIIRS shapefiles found under: {viirs_dir}\")\n",
    "    gdfs = [gpd.read_file(shp, engine=\"fiona\") for shp in shp_list]\n",
    "    gdf = gpd.pd.concat(gdfs, ignore_index=True)\n",
    "    return gdf\n",
    "\n",
    "def add_viirs_obstime(gdf: gpd.GeoDataFrame) -> gpd.GeoDataFrame:\n",
    "    \"\"\"\n",
    "    Expects:\n",
    "      - ACQ_DATE as datetime-like (or parseable)\n",
    "      - ACQ_TIME as 'HHMM' string (e.g., '1324')\n",
    "    \"\"\"\n",
    "    if not gnp_is_datetime64_any(gdf[\"ACQ_DATE\"]):\n",
    "        gdf[\"ACQ_DATE\"] = gpd.pd.to_datetime(gdf[\"ACQ_DATE\"])\n",
    "    def combine(row):\n",
    "        hm = row[\"ACQ_TIME\"]\n",
    "        hh = int(str(hm)[:2])\n",
    "        mm = int(str(hm)[2:])\n",
    "        return row[\"ACQ_DATE\"] + timedelta(hours=hh, minutes=mm)\n",
    "    gdf[\"observation_time\"] = gdf.apply(combine, axis=1)\n",
    "    gdf = gdf.sort_values(\"observation_time\").reset_index(drop=True)\n",
    "    # half-day bin index (integer): day_number*2 + (0 or 1)\n",
    "    gdf[\"half_day\"] = (gdf[\"observation_time\"].dt.day * 2 + (gdf[\"observation_time\"].dt.hour // 12)).astype(int)\n",
    "    return gdf\n",
    "\n",
    "def gnp_is_datetime64_any(series) -> bool:\n",
    "    return np.issubdtype(series.dtype, np.datetime64)\n",
    "\n",
    "def filter_viirs_to_extent(gdf: gpd.GeoDataFrame, extent_xyxy: List[float], target_crs: str) -> gpd.GeoDataFrame:\n",
    "    \"\"\"\n",
    "    extent in target_crs; points are assumed in EPSG:4326 (VIIRS); we project to target_crs then clip.\n",
    "    \"\"\"\n",
    "    gdf = gdf.to_crs(\"EPSG:4326\")  # ensure lon/lat first\n",
    "    gdf = gdf.to_crs(target_crs)\n",
    "    xmin, xmax, ymin, ymax = extent_xyxy\n",
    "    bbox = Polygon([(xmin,ymin),(xmax,ymin),(xmax,ymax),(xmin,ymax)])\n",
    "    return gdf[gdf.within(bbox)].copy()\n",
    "\n",
    "from pyproj import Geod\n",
    "\n",
    "# --- concave hulls per half-day (fallback to convex if needed) ---\n",
    "def viirs_concave_hulls_by_halfday(gdf: gpd.GeoDataFrame, ratio: float = 0.5, allow_holes: bool = True) -> Dict[int, Polygon]:\n",
    "    \"\"\"\n",
    "    Build concave hulls in EPSG:4326 for each half_day bin.\n",
    "    Falls back to convex hull (and tiny buffer if degenerate).\n",
    "    \"\"\"\n",
    "    hulls = {}\n",
    "    for half_id, sub in gdf.groupby(\"half_day\"):\n",
    "        pts = MultiPoint(list(sub.geometry))\n",
    "        try:\n",
    "            hull = concave_hull(pts, ratio=ratio, allow_holes=allow_holes) if len(sub) >= 3 else pts.convex_hull\n",
    "        except Exception:\n",
    "            hull = pts.convex_hull\n",
    "        if hull.geom_type in (\"Point\", \"LineString\"):\n",
    "            hull = hull.buffer(1e-9)  # tiny buffer in degrees to make a polygon\n",
    "        hulls[half_id] = hull\n",
    "    return hulls\n",
    "\n",
    "# --- geodesic areas (kmÂ²) from EPSG:4326 hulls ---\n",
    "_geod = Geod(ellps=\"WGS84\")\n",
    "\n",
    "def _geodesic_area_m2(poly: Polygon) -> float:\n",
    "    x, y = poly.exterior.xy\n",
    "    a_ext, _ = _geod.polygon_area_perimeter(x, y)\n",
    "    area = abs(a_ext)\n",
    "    for ring in poly.interiors:\n",
    "        xi, yi = ring.xy\n",
    "        a_h, _ = _geod.polygon_area_perimeter(xi, yi)\n",
    "        area -= abs(a_h)\n",
    "    return area\n",
    "\n",
    "def viirs_burn_area_history_from_hulls(hulls: Dict[int, Polygon]) -> Tuple[List[int], List[float]]:\n",
    "    \"\"\"\n",
    "    Returns (half_day_ids, areas_km2) using WGS84 geodesic area.\n",
    "    \"\"\"\n",
    "    times = sorted(hulls.keys())\n",
    "    areas_km2 = []\n",
    "    for t in times:\n",
    "        g = hulls[t]\n",
    "        if g.is_empty:\n",
    "            areas_km2.append(0.0)\n",
    "        elif isinstance(g, MultiPolygon):\n",
    "            areas_km2.append(sum(_geodesic_area_m2(p) for p in g.geoms) / 1e6)\n",
    "        else:  # Polygon\n",
    "            areas_km2.append(_geodesic_area_m2(g) / 1e6)\n",
    "    return times, areas_km2\n",
    "\n",
    "\n",
    "def rasterize_polygon_to_ref(poly: Polygon, ref_path: Path, burn_value: int = 1) -> np.ndarray:\n",
    "    with rasterio.open(ref_path) as ref:\n",
    "        out_shape = (ref.height, ref.width)\n",
    "        transform = ref.transform\n",
    "    if poly.is_empty:\n",
    "        return np.zeros(out_shape, dtype=np.uint8)\n",
    "    return rasterize([(poly, burn_value)], out_shape=out_shape, transform=transform,\n",
    "                     fill=0, dtype=\"uint8\")\n",
    "# -------------------------\n",
    "# ======= BURN HISTORY =====\n",
    "# -------------------------\n",
    "from typing import Optional, Tuple, List\n",
    "import numpy as np\n",
    "\n",
    "def burn_area_history_from_toa(\n",
    "    toa_array: np.ndarray,\n",
    "    pixel_area_m2: Optional[float] = None,\n",
    "    n_steps: Optional[int] = None\n",
    ") -> Tuple[List[float], List[float], List[float]]:\n",
    "    \"\"\"\n",
    "    Compute cumulative burned area vs time from a single per-pixel TOA raster.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    toa_array : np.ndarray\n",
    "        2D array (or masked array) where each finite element is the time of arrival.\n",
    "        NaNs / masked cells are treated as no-data.\n",
    "    pixel_area_m2 : float, optional\n",
    "        Area of one pixel (m^2). If None, areas are returned in pixel counts.\n",
    "    n_steps : int, optional\n",
    "        If provided, compute areas at this many evenly spaced time thresholds\n",
    "        between min and max TOA (faster, coarser). If None, use every unique TOA.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    times : List[float]\n",
    "        Time thresholds (either unique TOA values or evenly spaced thresholds).\n",
    "    areas : List[float]\n",
    "        Cumulative burned area at each time (same length as `times`).\n",
    "    \"\"\"\n",
    "    # Normalize input to a masked array and extract finite values\n",
    "    a = np.ma.asarray(toa_array)\n",
    "    finite_mask = np.isfinite(a) & (~a.mask if np.ma.isMaskedArray(a) else True)\n",
    "    vals = np.asarray(a[finite_mask], dtype=float)\n",
    "\n",
    "    if vals.size == 0:\n",
    "        return [], []\n",
    "\n",
    "    # Sort TOA values once; cumulative count yields burned pixels vs time\n",
    "    vals.sort()\n",
    "\n",
    "    # Drop negative \n",
    "    vals = vals[vals > 0]\n",
    "    if vals.size == 0:\n",
    "        return [], [], []\n",
    "\n",
    "    scale = pixel_area_m2 if pixel_area_m2 else 1.0\n",
    "\n",
    "    if n_steps is None:\n",
    "        unique_times, counts = np.unique(vals, return_counts=True)\n",
    "        cum_counts = np.cumsum(counts)\n",
    "        areas = (cum_counts * scale).astype(float).tolist()\n",
    "        return unique_times.tolist(), cum_counts.tolist(), areas\n",
    "    else:\n",
    "        # Coarse curve at evenly spaced thresholds (much faster if many unique TOAs)\n",
    "        t_min, t_max = float(vals[0]), float(vals[-1])\n",
    "        thresholds = np.linspace(t_min, t_max, int(n_steps))\n",
    "        # Number of vals <= threshold via binary search\n",
    "        idx = np.searchsorted(vals, thresholds, side=\"right\")\n",
    "        areas = (idx * scale).astype(float).tolist()\n",
    "        return thresholds.tolist(), areas\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# ====== PLOTTING (TOA vs VIIRS)\n",
    "# -------------------------\n",
    "def plot_burnt_map_from_toa(\n",
    "    ax: plt.Axes,\n",
    "    toa_array: np.ndarray,\n",
    "    time_now: float,\n",
    "    extent,\n",
    "    alpha: float = 0.4\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Show burned region where TOA <= time_now on the same grid/extent as TOA.\n",
    "    \"\"\"\n",
    "    # finite domain + threshold\n",
    "    finite = np.isfinite(toa_array) & (~toa_array.mask if np.ma.isMaskedArray(toa_array) else True)\n",
    "    burned = (finite & (toa_array <= time_now)).astype(float)\n",
    "    burned[burned == 0] = np.nan\n",
    "    ax.imshow(burned, extent=extent, origin=\"upper\", alpha=alpha, cmap=\"Greys\", vmin=0, vmax=1)\n",
    "\n",
    "\n",
    "def plot_viirs_points(ax: plt.Axes, gdf_proj: gpd.GeoDataFrame, **kwargs):\n",
    "    xs = gdf_proj.geometry.x.values\n",
    "    ys = gdf_proj.geometry.y.values\n",
    "    ax.scatter(xs, ys, **kwargs)\n",
    "\n",
    "# -------------------------\n",
    "# ====== KAPPA METRIC ======\n",
    "# -------------------------\n",
    "def calc_cohen_kappa_for_case(phi_paths: List[Path], hulls_by_halfday: Dict[int, Polygon]) -> List[float]:\n",
    "    \"\"\"\n",
    "    For each Ï† raster, find nearest half_day hull, rasterize it on Ï† grid,\n",
    "    compute kappa between (Ï†<=0) vs (hull raster == 1) over valid pixels.\n",
    "    \"\"\"\n",
    "    half_ids_sorted = sorted(hulls_by_halfday.keys())\n",
    "    kappas = []\n",
    "    used_half = set()\n",
    "    for phi_path in phi_paths:\n",
    "        # match by numeric timestamp in filename\n",
    "        ts = extract_timestamp_from_phi_name(phi_path.name)\n",
    "        # pick nearest half-day id (proxy). If none, skip.\n",
    "        if not half_ids_sorted:\n",
    "            kappas.append(float(\"nan\"))\n",
    "            continue\n",
    "        best = min(half_ids_sorted, key=lambda h: abs(h - (ts if ts is not None else half_ids_sorted[0])))\n",
    "        # avoid reusing exact same half bin if you want 1-1 matching\n",
    "        # (comment out following two lines to allow reuse)\n",
    "        # if best in used_half and len(half_ids_sorted) > 1:\n",
    "        #     candidates = [h for h in half_ids_sorted if h not in used_half]\n",
    "        #     if candidates: best = min(candidates, key=lambda h: abs(h - ts))\n",
    "        used_half.add(best)\n",
    "\n",
    "        viirs_bin = rasterize_polygon_to_ref(hulls_by_halfday[best], phi_path, burn_value=1)\n",
    "        phi_bin, valid = phi_to_binary(phi_path)\n",
    "\n",
    "        y_true = phi_bin[valid].ravel()\n",
    "        y_pred = viirs_bin[valid].ravel()\n",
    "        kappa = cohen_kappa_score(y_true, y_pred)\n",
    "        kappas.append(float(kappa))\n",
    "        print(f\"âœ… {phi_path.name}: half_day={best}, Kappa={kappa:.4f}, Burned_px={int(phi_bin.sum())}\")\n",
    "    return kappas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f83797-ef81-43a7-9572-5c6faa6f9e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "Complete, runnable postprocess script for one ELMFIRE case.\n",
    "\n",
    "What it does:\n",
    "- Loads/plots fuel map (categorized colormap)\n",
    "- Loads weather rasters and plots histograms (WS, WD, M1, M10, M100)\n",
    "- Loads TOA stack, builds burn-area history\n",
    "- Loads VIIRS points, filters to extent, groups by half-day, convex hulls, burn-area history\n",
    "- Overlays VIIRS dots on base map and simulated burned extent for selected times\n",
    "- Computes Cohen's Kappa per selected frames by rasterizing VIIRS hulls and comparing to Ï†-binary\n",
    "- Saves figures + metrics.json\n",
    "\n",
    "Adjust the PATH CONSTANTS block for your case.\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "import os, re, glob, json, math\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "import rasterio\n",
    "from rasterio.features import rasterize\n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "from rasterio.enums import Resampling as ResampEnum\n",
    "\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, Polygon, MultiPoint\n",
    "from shapely.ops import unary_union\n",
    "\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from datetime import timedelta\n",
    "\n",
    "# -------------------------\n",
    "# ===== PATH CONSTANTS ====\n",
    "# -------------------------\n",
    "CASE_ROOT = Path(\"/global/home/users/yirenqin712/scratch/yirenqin712/ELMFIRE_SIMULATION/VnV_Suite/tubbs_fire\").resolve()\n",
    "\n",
    "# Inputs\n",
    "FUELMAP_PATH   = CASE_ROOT / \"data/fuels_and_topography/fbfm40b.tif\"\n",
    "WX_WS_PATH     = CASE_ROOT / \"data/weather/ws.tif\"\n",
    "WX_WD_PATH     = CASE_ROOT / \"data/weather/wd.tif\"\n",
    "WX_M1_PATH     = CASE_ROOT / \"data/weather/m1.tif\"\n",
    "WX_M10_PATH    = CASE_ROOT / \"data/weather/m10.tif\"\n",
    "WX_M100_PATH   = CASE_ROOT / \"data/weather/m100.tif\"\n",
    "TOA_GLOB       = str(CASE_ROOT / \"outputs\" / \"time_of_arrival_*.tif\")\n",
    "PHI_GLOB       = str(CASE_ROOT / \"outputs\" / \"phi_0000001_*.tif\")\n",
    "VIIRS_DIR      = CASE_ROOT / \"data/viirs_observation\"                      # expects viirs_*.shp\n",
    "\n",
    "# Outputs\n",
    "FIG_DIR = CASE_ROOT / \"figures\"\n",
    "REP_DIR = CASE_ROOT / \"report\"\n",
    "for p in [FIG_DIR, REP_DIR]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Map extent + CRS for plotting overlays (adjust if needed)\n",
    "# [left, right, bottom, top] in projected CRS (e.g., UTM)\n",
    "# If you already know your extent, set it here; otherwise it's computed from fuel map reproject.\n",
    "MAP_CRS = \"EPSG:32610\"  # UTM zone (adjust per case)\n",
    "OUT_CRS = \"EPSG:4326\"   # Plotting in lon/lat for base map\n",
    "MAP_EXTENT_OVERRIDE: Optional[List[float]] = None  # or [xmin, xmax, ymin, ymax] in MAP_CRS\n",
    "\n",
    "# -------------------------\n",
    "# ====== UTILITIES =========\n",
    "# -------------------------\n",
    "\n",
    "def save_fig(fig, name: str):\n",
    "    \"\"\"Save a figure into the case-local figures/ folder as PDF and close it.\"\"\"\n",
    "    out = FIG_DIR / f\"{name}.pdf\"\n",
    "    fig.savefig(out, format=\"pdf\")  # no bbox_inches\n",
    "    plt.close(fig)\n",
    "    return out\n",
    "\n",
    "# ---- 1) Fuel map base layer\n",
    "fig, ax = plt.subplots(figsize=(11, 10))\n",
    "_, ax, extent_ll = plot_fuel_map(FUELMAP_PATH, ax=ax, show_colorbar=True, dst_crs=OUT_CRS)\n",
    "ax.set_xlabel('Longitude [$^\\circ$]')\n",
    "ax.set_ylabel('Latitude [$^\\circ$]')\n",
    "out=save_fig(fig, \"fuelmap_categorical\")\n",
    "print(f\"Fuel map saved to {out}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9056eaaf-2a95-401f-916f-3c326edb86b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- 2) Weather histograms\n",
    "wx_list = [\n",
    "    (WX_WS_PATH, \"Wind Speed [mph]\"),\n",
    "    (WX_WD_PATH, \"Wind Direction [Â°]\"),\n",
    "    (WX_M1_PATH, \"1-hr Dead Fuel Moisture [%]\"),\n",
    "    (WX_M10_PATH, \"10-hr Dead Fuel Moisture [%]\"),\n",
    "    (WX_M100_PATH, \"100-hr Dead Fuel Moisture [%]\"),\n",
    "]\n",
    "for path, xlabel in wx_list:\n",
    "    fig, ax = plt.subplots(figsize=(6,4))\n",
    "    plot_wx_hist(ax, path, bins=60)\n",
    "    ax.set_xlabel(xlabel)\n",
    "    save_fig(fig, f\"hist_{path.stem}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5795018-3f2e-41f9-a8fc-09eab896c07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- 3) Load TOA + compute pixel area\n",
    "# If you have one grid definition, we can estimate pixel area from transform\n",
    "phi_paths = load_phi_paths(PHI_GLOB)\n",
    "with rasterio.open(phi_paths[0]) as src0:\n",
    "    px_area = abs(src0.transform.a * src0.transform.e)  # (m/px)*(m/px) if UTM/proj in meters\n",
    "\n",
    "toa_paths, toa_arrays, toa_times, toa_transform, toa_meta = load_toa_stack(TOA_GLOB)\n",
    "toa_times_hist, count, toa_area_hist = burn_area_history_from_toa(toa_arrays, pixel_area_m2=px_area)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840b363b-7a0c-4d58-8095-4dc57ff7ab45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- 4) VIIRS: load, timebin (half-day), filter to map extent, build hulls\n",
    "viirs_gdf = load_viirs_points(VIIRS_DIR)\n",
    "viirs_gdf = add_viirs_obstime(viirs_gdf)\n",
    "\n",
    "# Figure out a target extent in projected CRS for point filtering\n",
    "# If override is given, use it. Else derive fuel map extent in MAP_CRS\n",
    "# fmap_arr, fmap_transform, fmap_meta = read_raster(FUELMAP_PATH)\n",
    "# fmap_extent_mapcrs = array_extent(fmap_transform, fmap_meta[\"width\"], fmap_meta[\"height\"])\n",
    "# target_extent = MAP_EXTENT_OVERRIDE if MAP_EXTENT_OVERRIDE else fmap_extent_mapcrs\n",
    "\n",
    "# viirs_filtered = filter_viirs_to_extent(viirs_gdf, target_extent, target_crs=MAP_CRS)\n",
    "hulls_by_half = viirs_concave_hulls_by_halfday(viirs_gdf)\n",
    "viirs_times, viirs_areas = viirs_burn_area_history_from_hulls(hulls_by_half)  # area in map CRS units (m^2 if UTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88b838c-70a0-4629-9b97-33aac9a9c292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- 5) VIIRS vs TOA overlays for first 3 half-day bins (if available)\n",
    "# A proper timezone-aware start time (Los Angeles)\n",
    "start_time = datetime(2017, 10, 8, 21, 43, tzinfo=ZoneInfo(\"America/Los_Angeles\"))\n",
    "\n",
    "# Representative datetime for each half_day bin (median of obs in that bin)\n",
    "half2time = (viirs_filtered\n",
    "             .groupby(\"half_day\")[\"observation_time\"]\n",
    "             .median()\n",
    "             .to_dict())\n",
    "\n",
    "# Get TOA grid's extent + CRS (we'll draw everything in the TOA CRS)\n",
    "with rasterio.open(toa_paths[0]) as ref:\n",
    "    target_crs = ref.crs.to_string()\n",
    "    extent = array_extent(ref.transform, ref.width, ref.height)\n",
    "\n",
    "# Reproject fuel map to the TOA CRS for consistent overlay (no colorbar in small multiples)\n",
    "n_show = min(3, len(viirs_times))\n",
    "fig, axs = plt.subplots(1, n_show, figsize=(6*n_show, 6))\n",
    "if n_show == 1:\n",
    "    axs = [axs]\n",
    "\n",
    "for i, ax in enumerate(axs):\n",
    "    half_id = viirs_times[i]  # e.g., 2*day + (0 or 1)\n",
    "    # Convert VIIRS bin time to seconds since start_time\n",
    "    t_obs = half2time[half_id].tz_convert(\"America/Los_Angeles\") if hasattr(half2time[half_id], \"tz_convert\") else half2time[half_id]\n",
    "    if t_obs.tzinfo is None:\n",
    "        # if your observation_time is naive, assume LA timezone\n",
    "        t_obs = t_obs.replace(tzinfo=ZoneInfo(\"America/Los_Angeles\"))\n",
    "    time_now_sec = (t_obs - start_time).total_seconds()\n",
    "\n",
    "    # Base fuel map in TOA CRS\n",
    "    _im, _ax, _ = plot_fuel_map(FUELMAP_PATH, ax=ax, show_colorbar=False, dst_crs=target_crs)\n",
    "\n",
    "    # Burned map from a single TOA field (choose the TOA field you actually use)\n",
    "    # If you loaded one per-pixel TOA raster, pick it here:\n",
    "    toa_field = toa_arrays[0] if len(toa_arrays) >= 1 else toa_arrays  # 2D masked/ndarray\n",
    "    plot_burnt_map_from_toa(ax, toa_field, time_now_sec, extent, alpha=0.25)\n",
    "\n",
    "    # VIIRS points for this bin â†’ TOA CRS\n",
    "    sub_pts = viirs_filtered[viirs_filtered[\"half_day\"] == half_id].to_crs(target_crs)\n",
    "    plot_viirs_points(ax, sub_pts, s=4, marker='s')\n",
    "\n",
    "    ax.set_title(f\"TOA vs VIIRS (half_day={half_id})\")\n",
    "    ax.set_aspect(\"equal\")\n",
    "\n",
    "save_fig(fig, \"simu_vs_viirs_examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6dc3ff-b87b-4a7a-8b87-22ee4c02e987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- 6) Burn area history plot\n",
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "ax.plot(np.array(toa_times_hist)/3600.0, np.array(toa_area_hist)/1e6, label=\"Simulated (TOA)\", lw=2)\n",
    "ax.plot(viirs_times, np.array(viirs_areas), label=\"Observed (VIIRS hull)\", lw=2)\n",
    "ax.set_xlabel(\"Time [s]\")\n",
    "ax.set_ylabel(\"Burned area [kmÂ²]\")\n",
    "ax.legend()\n",
    "save_fig(fig, \"burn_area_history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4efc40-9047-4d22-93fd-b27cee180905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- 7) Cohen's Kappa (per Ï† slice vs nearest half-day VIIRS hull)\n",
    "kappas = calc_cohen_kappa_for_case(phi_paths, hulls_by_half)\n",
    "metrics = {f\"kappa_{i+1}\": (None if (i>=len(kappas) or np.isnan(kappas[i])) else round(float(kappas[i]), 6))\n",
    "           for i in range(min(3, len(kappas)))}\n",
    "\n",
    "# ---- 8) Save metrics + simple LaTeX snippets (optional)\n",
    "(OUT_DIR / \"metrics.json\").write_text(json.dumps(metrics, indent=2), encoding=\"utf-8\")\n",
    "print(\"[OK] Postprocess complete.\")\n",
    "print(f\"  - Figures: {FIG_DIR}\")\n",
    "print(f\"  - Metrics JSON: {OUT_DIR/'metrics.json'}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
